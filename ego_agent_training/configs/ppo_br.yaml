defaults:
  - task: lbf # task configs
  - hydra: hydra_simple
  - _self_         # Ensures that values in this file override imported ones if needed

ENV_NAME: ${task.ENV_NAME}
ENV_KWARGS: ${task.ENV_KWARGS}
ROLLOUT_LENGTH: ${task.ROLLOUT_LENGTH}
TASK_NAME: ${task.TASK_NAME}

partner_agent:
  ippo_mlp: # lbf policy!
    path: "eval_teammates/lbf/ippo/2025-04-21_23-41-17/saved_train_run"
    actor_type: mlp
    ckpt_key: final_params
    idx_list: [0] # load in only a single policy checkpoint
    test_mode: true
    # provide any necessary args to initialize the agent here
    # ex) S5_ACTOR_CRITIC_HIDDEN_DIM: 64 
    # defaults for each actor type will be used if no args are provided

algorithm:
  ALG: ppo_br
  EGO_ACTOR_TYPE: s5 # options: s5, mlp, rnn
  TOTAL_TIMESTEPS: 3e5
  TRAIN_SEED: 12345
  NUM_EGO_TRAIN_SEEDS: 1
  NUM_EVAL_EPISODES: 20
  NUM_CHECKPOINTS: 5
  NUM_ENVS: 16
  ENV_NAME: ${ENV_NAME}
  ENV_KWARGS: ${ENV_KWARGS}
  ROLLOUT_LENGTH: ${ROLLOUT_LENGTH}
  LR: 1.e-4 
  UPDATE_EPOCHS: 15
  NUM_MINIBATCHES: 4
  GAMMA: 0.99
  GAE_LAMBDA: 0.95
  CLIP_EPS: 0.05
  ENT_COEF: 0.01
  VF_COEF: 1.0
  MAX_GRAD_NORM: 1.0
  ANNEAL_LR: true

# WandB Params
logger: 
  project: open-ended-aht
  entity: aht-project
  mode: offline # options: online, offline, disabled
  verbose: true
  log_train_out: false # whether to log the out dictionary

# Local logger
local_logger:
  save_figures: true # currently unused
  save_train_out: true

name: ${TASK_NAME}/${algorithm.ALG}_${algorithm.EGO_ACTOR_TYPE}
