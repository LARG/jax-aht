defaults:
  - hydra: hydra_simple
  - _self_

# ENV_NAME: lbf
# ROLLOUT_LENGTH: 128
# ENV_KWARGS: {}

ENV_NAME: overcooked-v1
ROLLOUT_LENGTH: 100
ENV_KWARGS: {
  layout: "cramped_room",
  max_steps: 100
}

# name: brdiv
name: ${ENV_KWARGS.layout}/brdiv

algorithm:
  ALG: brdiv
  PARTNER_POP_SIZE: 5
  NUM_EVAL_EPISODES: 20
  TRAIN_SEED: 38410
  NUM_ENVS_SP: 32
  NUM_ENVS_XP: 32
  # SP weight = 1 + 2*XP weight. 
  # Thus, as XP weight -> 0, SP/(SP+XP) -> 1.
  # If XP weight -> infinity, XP/(SP+XP) -> 1/3, and SP/(SP+XP) -> 2/3.
  XP_LOSS_WEIGHTS: 10 
  ENV_NAME: ${ENV_NAME}
  ENV_KWARGS: ${ENV_KWARGS}
  ROLLOUT_LENGTH: ${ROLLOUT_LENGTH}
  TOTAL_TIMESTEPS: 1e8  # divided among each pair of BR and Conf agents
  LR: 5.e-4
  UPDATE_EPOCHS: 15
  NUM_MINIBATCHES: 16
  NUM_CHECKPOINTS: 5
  GAMMA: 0.99
  GAE_LAMBDA: 0.95
  CLIP_EPS: 0.05
  ENT_COEF: 0.01
  VF_COEF: 1.0
  MAX_GRAD_NORM: 1.0
  ANNEAL_LR: false # TODO: check if we should anneal the learning rate

# wandb settings
logger: 
  load_dir: brdiv
  project: open-ended-aht
  entity: aht-project
  mode: online # options: online, offline, disabled
  verbose: true
  log_train_out: true # whether to log the out dictionary

# Local logger
local_logger:
  save_figures: false # unused
  save_train_out: true
