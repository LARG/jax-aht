# @package algorithm
# ^ tells hydra to place these value directly under algorithm key
ALG: oe_persistent_lagrange
TIMESTEPS_PER_ITER_PARTNER: 1.5e6 # per iter of open-ended training, divided between conf-br and conf-ego and between all partner seeds
TIMESTEPS_PER_ITER_EGO: 1e6
NUM_OPEN_ENDED_ITERS: 30
NUM_CHECKPOINTS: 5 # per iter of open-ended training
PARTNER_POP_SIZE: 1 # true pop size is PARTNER_POP_SIZE * NUM_CHECKPOINTS per iter of open-ended training
CONF_BR_WEIGHT: 0.5 # conf-ego weight set to 1 - conf-br weight
REINIT_CONF: true # whether to reinitialize the confederate policy each iteration of open-ended training
REINIT_BR: true # whether to reinitialize the br policy each iteration of open-ended training
# lagrange args
LAGRANGE_MULTIPLIER_LR: 0.05
LAGRANGE_USE_TARGET_RETURNS: false
# buffer args
SAMPLING_STRATEGY: uniform # 'plr' or 'uniform'
STALENESS_COEF: 0.3 # used only for 'plr' sampling strategy
SCORE_TEMP: 1.0 # used only for 'plr' sampling strategy, currently ineffective
NUM_ENVS: 16
LR: 1.e-4
UPDATE_EPOCHS: 15
NUM_MINIBATCHES: 4
GAMMA: 0.99
GAE_LAMBDA: 0.95
CLIP_EPS: 0.05
ENT_COEF: 0.01
VF_COEF: 1.0
MAX_GRAD_NORM: 1.0
ANNEAL_LR: false
